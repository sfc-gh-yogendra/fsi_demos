---
description: Cross-domain intelligence architecture for Glacier First Bank with shared ecosystem connections
alwaysApply: false
---
# Glacier First Bank — Cross-Domain Intelligence Architecture

## Overview
This rule defines the architecture for cross-domain intelligence that enables agents to discover and analyze risk contagion, entity relationships, and multi-step reasoning patterns across AML/KYC, Credit Analysis, and future phases through shared ecosystem connections.

## Cross-Domain Intelligence Principles

### Shared Ecosystem Foundation
The architecture is built on the principle that financial institutions operate within interconnected business ecosystems where:

1. **Vendor Dependencies**: Multiple clients share common suppliers, logistics partners, and service providers
2. **Industry Clustering**: Companies in similar sectors face correlated risks and opportunities
3. **Geographic Correlation**: Entities in the same regions share regulatory environments and market conditions
4. **Regulatory Cascade**: Policy changes affect multiple business functions simultaneously
5. **Temporal Risk Evolution**: Risk patterns emerge and propagate across different time horizons

### Multi-Step Reasoning Framework
Agents perform sophisticated analysis through:

1. **Evidence Gathering**: Collect data from multiple structured and unstructured sources
2. **Pattern Recognition**: Identify relationships and dependencies across domains
3. **Contradiction Synthesis**: Reconcile conflicting signals and assess uncertainty
4. **Risk Propagation**: Model how risks cascade through business networks
5. **Impact Assessment**: Quantify potential business and financial implications
6. **Recommendation Generation**: Provide actionable insights with clear rationale

## Shared Ecosystem Entity Network

### Core Risk Propagation Entities

#### Northern Supply Chain Ltd (Primary Risk Vector)
```yaml
entity_profile:
  entity_id: "NSC_UK_001"
  name: "Northern Supply Chain Ltd"
  country: "GBR"
  industry: "Logistics & Transportation"
  regulatory_status: "ACTIVE"
  
risk_characteristics:
  labor_dispute_risk: "HIGH"
  geopolitical_exposure: "MEDIUM"
  esg_compliance_status: "UNDER_REVIEW"
  financial_health: "STABLE"
  operational_dependencies: ["Port of Rotterdam", "Channel Tunnel", "German Autobahn Network"]

client_dependencies:
  - entity: "Global Trade Ventures S.A."
    dependency_type: "PRIMARY_LOGISTICS"
    dependency_strength: 0.85  # 85% of logistics operations
    revenue_impact: 60
    alternative_sourcing_time: "90-120 days"
    
  - entity: "Innovate GmbH"
    dependency_type: "SECONDARY_FULFILLMENT"
    dependency_strength: 0.25  # 25% of fulfillment operations
    revenue_impact: 15
    alternative_sourcing_time: "30-45 days"
    
  - entity: "EuroTech Industries"
    dependency_type: "REGIONAL_DISTRIBUTION"
    dependency_strength: 0.45  # 45% of European distribution
    revenue_impact: 25
    alternative_sourcing_time: "60-90 days"

risk_scenarios:
  operational_disruption:
    probability: "MEDIUM"
    triggers: ["Labor strikes", "Brexit-related delays", "Infrastructure failures"]
    impact_timeline: "30-90 days"
    mitigation_complexity: "HIGH"
    
  insolvency:
    probability: "LOW"
    triggers: ["Major client loss", "Regulatory sanctions", "Economic downturn"]
    impact_timeline: "6-12 months"
    recovery_options: ["Asset acquisition", "Service replacement", "Client diversification"]
```

#### Regulatory Environment Correlations
```yaml
regulatory_ecosystem:
  eu_esg_directive_2024:
    affected_entities: ["Global Trade Ventures S.A.", "Innovate GmbH", "Northern Supply Chain Ltd"]
    compliance_deadline: "2025-01-01"
    impact_areas: ["ESG reporting", "Supply chain transparency", "Carbon footprint disclosure"]
    compliance_cost_estimate: "€150K-€500K per entity"
    
  basel_iii_capital_requirements:
    affected_functions: ["Credit Analysis", "Portfolio Risk Management"]
    implementation_date: "2024-01-01"
    impact_areas: ["Risk weighting", "Capital allocation", "Stress testing"]
    
  eu_aml_directive_update:
    affected_functions: ["AML/KYC", "Transaction Monitoring"]
    consultation_period: "2024-Q4"
    impact_areas: ["Enhanced due diligence", "Beneficial ownership", "Digital identity"]
```

## Cross-Domain Query Patterns

### Risk Contagion Analysis Queries
```sql
-- Pattern 1: Vendor Risk Propagation
WITH shared_vendor_exposure AS (
    SELECT 
        r.related_entity_name as vendor_name,
        COUNT(DISTINCT r.primary_entity_name) as affected_clients,
        SUM(r.risk_impact_score) as total_risk_exposure,
        AVG(r.risk_impact_score) as average_risk_impact
    FROM SEMANTIC_VIEW(
        BANK_AI_DEMO.SEMANTIC_LAYER.ecosystem_risk_sv
        METRICS relationship_count, average_risk_impact
        DIMENSIONS primary_entity_name, related_entity_name, relationship_type, relationship_strength
        FILTERS relationship_type = 'VENDOR' AND relationship_strength IN ('PRIMARY', 'SECONDARY')
    ) r
    GROUP BY r.related_entity_name
    HAVING COUNT(DISTINCT r.primary_entity_name) > 1
),
client_financial_exposure AS (
    SELECT 
        c.applicant_name,
        c.requested_amount,
        c.debt_to_equity,
        c.client_concentration
    FROM SEMANTIC_VIEW(
        BANK_AI_DEMO.SEMANTIC_LAYER.credit_risk_sv
        METRICS requested_amount, debt_to_equity, client_concentration
        DIMENSIONS applicant_name
    ) c
),
compliance_risk_overlay AS (
    SELECT 
        cr.entity_name,
        cr.aml_flag_count,
        cr.risk_rating,
        cr.regulatory_status
    FROM SEMANTIC_VIEW(
        BANK_AI_DEMO.SEMANTIC_LAYER.customer_risk_sv
        METRICS aml_flag_count
        DIMENSIONS entity_name, risk_rating, regulatory_status
    ) cr
)
SELECT 
    sve.vendor_name,
    sve.affected_clients,
    sve.total_risk_exposure,
    cfe.applicant_name,
    cfe.requested_amount,
    cfe.debt_to_equity,
    cro.aml_flag_count,
    cro.risk_rating,
    -- Calculate composite risk score
    (sve.average_risk_impact * 0.4 + 
     CASE WHEN cfe.debt_to_equity > 3.0 THEN 0.3 ELSE 0.1 END +
     CASE WHEN cro.aml_flag_count > 0 THEN 0.3 ELSE 0.0 END) as composite_risk_score
FROM shared_vendor_exposure sve
JOIN client_financial_exposure cfe ON sve.vendor_name = 'Northern Supply Chain Ltd'
JOIN compliance_risk_overlay cro ON cfe.applicant_name = cro.entity_name
ORDER BY composite_risk_score DESC;
```

### Regulatory Impact Cascade Analysis
```sql
-- Pattern 2: Cross-Domain Regulatory Impact
WITH regulatory_changes AS (
    SELECT 
        regulation_type,
        title,
        effective_date,
        impact_level,
        affected_institutions
    FROM BANK_AI_DEMO.RAW_DATA.TR_REGULATORY_UPDATES
    WHERE effective_date >= CURRENT_DATE()
    AND regulation_type IN ('Banking', 'AML', 'ESG')
),
credit_portfolio_impact AS (
    SELECT 
        COUNT(*) as affected_applications,
        SUM(requested_amount) as total_exposure,
        AVG(debt_to_equity) as avg_leverage
    FROM SEMANTIC_VIEW(
        BANK_AI_DEMO.SEMANTIC_LAYER.credit_risk_sv
        METRICS requested_amount, debt_to_equity
        DIMENSIONS applicant_name, esg_rating
        FILTERS esg_rating IN ('C+', 'C', 'D')
    )
),
compliance_caseload_impact AS (
    SELECT 
        COUNT(*) as active_edd_cases,
        SUM(aml_flag_count) as total_aml_flags
    FROM SEMANTIC_VIEW(
        BANK_AI_DEMO.SEMANTIC_LAYER.customer_risk_sv
        METRICS aml_flag_count
        DIMENSIONS entity_name, kyc_status, regulatory_status
        FILTERS kyc_status = 'REQUIRES_EDD' OR regulatory_status = 'UNDER_REVIEW'
    )
)
SELECT 
    rc.regulation_type,
    rc.title,
    rc.effective_date,
    rc.impact_level,
    cpi.affected_applications,
    cpi.total_exposure,
    cci.active_edd_cases,
    cci.total_aml_flags,
    -- Estimate implementation effort
    CASE 
        WHEN rc.impact_level = 'High' AND rc.regulation_type = 'ESG' 
        THEN cpi.affected_applications * 40  -- 40 hours per application
        WHEN rc.impact_level = 'High' AND rc.regulation_type = 'AML'
        THEN cci.active_edd_cases * 20       -- 20 hours per case
        ELSE 0
    END as estimated_implementation_hours
FROM regulatory_changes rc
CROSS JOIN credit_portfolio_impact cpi
CROSS JOIN compliance_caseload_impact cci
ORDER BY rc.effective_date, rc.impact_level DESC;
```

## Agent Orchestration Patterns

### Cross-Domain Intelligence Workflow
```python
class CrossDomainIntelligenceOrchestrator:
    """Orchestrates cross-domain intelligence queries across multiple agents and semantic views."""
    
    def __init__(self, session: Session):
        self.session = session
        self.semantic_views = {
            'credit_risk': 'BANK_AI_DEMO.SEMANTIC_LAYER.credit_risk_sv',
            'customer_risk': 'BANK_AI_DEMO.SEMANTIC_LAYER.customer_risk_sv',
            'ecosystem_risk': 'BANK_AI_DEMO.SEMANTIC_LAYER.ecosystem_risk_sv'
        }
        self.search_services = {
            'compliance_docs': 'BANK_AI_DEMO.AGENT_FRAMEWORK.compliance_docs_search_svc',
            'credit_policy': 'BANK_AI_DEMO.AGENT_FRAMEWORK.credit_policy_search_svc',
            'news_research': 'BANK_AI_DEMO.AGENT_FRAMEWORK.news_research_search_svc'
        }
    
    def analyze_vendor_risk_contagion(self, vendor_name: str) -> Dict[str, Any]:
        """Analyze risk contagion through shared vendor relationships."""
        
        # Step 1: Identify affected clients
        affected_clients = self._get_vendor_clients(vendor_name)
        
        # Step 2: Assess financial exposure
        financial_exposure = self._assess_client_financial_risk(affected_clients)
        
        # Step 3: Check compliance status
        compliance_status = self._check_compliance_risk(affected_clients)
        
        # Step 4: Analyze news sentiment
        news_sentiment = self._analyze_vendor_news_sentiment(vendor_name)
        
        # Step 5: Synthesize cross-domain intelligence
        risk_assessment = self._synthesize_cross_domain_risk(
            affected_clients, financial_exposure, compliance_status, news_sentiment
        )
        
        return risk_assessment
    
    def _get_vendor_clients(self, vendor_name: str) -> List[Dict[str, Any]]:
        """Get all clients with relationships to specified vendor."""
        
        query = f"""
        SELECT * FROM SEMANTIC_VIEW(
            {self.semantic_views['ecosystem_risk']}
            METRICS relationship_count, average_risk_impact, vendor_dependency_count
            DIMENSIONS primary_entity_name, relationship_type, relationship_strength
            FILTERS related_entity_name = '{vendor_name}' AND relationship_type = 'VENDOR'
        )
        """
        
        return self.session.sql(query).collect()
    
    def _assess_client_financial_risk(self, clients: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Assess financial risk metrics for affected clients."""
        
        client_names = [client['PRIMARY_ENTITY_NAME'] for client in clients]
        client_filter = "', '".join(client_names)
        
        query = f"""
        SELECT * FROM SEMANTIC_VIEW(
            {self.semantic_views['credit_risk']}
            METRICS dscr, debt_to_equity, client_concentration, requested_amount
            DIMENSIONS applicant_name, industry, esg_rating
            FILTERS applicant_name IN ('{client_filter}')
        )
        """
        
        return self.session.sql(query).collect()
    
    def _synthesize_cross_domain_risk(self, clients, financial, compliance, news) -> Dict[str, Any]:
        """Synthesize findings from multiple domains into unified risk assessment."""
        
        synthesis = {
            'affected_clients': len(clients),
            'total_financial_exposure': sum([f.get('REQUESTED_AMOUNT', 0) for f in financial]),
            'high_risk_clients': len([c for c in compliance if c.get('AML_FLAG_COUNT', 0) > 0]),
            'average_sentiment': sum([n.get('sentiment_score', 0) for n in news]) / len(news) if news else 0,
            'risk_scenarios': self._generate_risk_scenarios(clients, financial, compliance),
            'recommendations': self._generate_cross_domain_recommendations(clients, financial, compliance)
        }
        
        return synthesis
```

### Multi-Step Reasoning Implementation
```python
def execute_multi_step_analysis(user_query: str, context: Dict[str, Any]) -> str:
    """Execute multi-step reasoning analysis across domains."""
    
    reasoning_steps = []
    
    # Step 1: Query Understanding and Planning
    analysis_plan = parse_cross_domain_query(user_query)
    reasoning_steps.append({
        'step': 1,
        'action': 'Query Planning',
        'description': f"Identified need for {', '.join(analysis_plan['required_domains'])} analysis",
        'tools_planned': analysis_plan['tools_required']
    })
    
    # Step 2: Structured Data Analysis
    if 'structured_analysis' in analysis_plan['required_domains']:
        structured_results = execute_semantic_view_queries(analysis_plan['structured_queries'])
        reasoning_steps.append({
            'step': 2,
            'action': 'Structured Data Analysis',
            'description': f"Analyzed {len(structured_results)} data points from semantic views",
            'key_findings': extract_key_findings(structured_results)
        })
    
    # Step 3: Unstructured Data Search
    if 'unstructured_analysis' in analysis_plan['required_domains']:
        search_results = execute_cortex_search_queries(analysis_plan['search_queries'])
        reasoning_steps.append({
            'step': 3,
            'action': 'Document Analysis',
            'description': f"Searched {len(search_results)} documents for relevant context",
            'key_findings': extract_document_insights(search_results)
        })
    
    # Step 4: Cross-Domain Correlation
    if len(analysis_plan['required_domains']) > 1:
        correlations = identify_cross_domain_patterns(structured_results, search_results)
        reasoning_steps.append({
            'step': 4,
            'action': 'Cross-Domain Correlation',
            'description': "Identified relationships and dependencies across data sources",
            'correlations': correlations
        })
    
    # Step 5: Contradiction Analysis
    contradictions = identify_contradictory_evidence(structured_results, search_results)
    if contradictions:
        reasoning_steps.append({
            'step': 5,
            'action': 'Contradiction Analysis',
            'description': "Identified and assessed conflicting evidence",
            'contradictions': contradictions,
            'resolution_approach': resolve_contradictions(contradictions)
        })
    
    # Step 6: Risk Assessment Synthesis
    risk_assessment = synthesize_risk_assessment(reasoning_steps, context)
    reasoning_steps.append({
        'step': 6,
        'action': 'Risk Assessment Synthesis',
        'description': "Integrated findings into comprehensive risk assessment",
        'final_assessment': risk_assessment
    })
    
    # Generate final response with reasoning transparency
    response = format_multi_step_response(reasoning_steps, user_query)
    
    return response
```

## Contradictory Evidence Synthesis Patterns

### Evidence Conflict Resolution Framework
```python
class ContradictoryEvidenceSynthesizer:
    """Handles synthesis of conflicting evidence across data sources."""
    
    def __init__(self):
        self.evidence_weights = {
            'financial_statements': 0.9,    # High reliability
            'news_sentiment': 0.6,          # Medium reliability
            'regulatory_status': 0.95,      # Very high reliability
            'historical_performance': 0.8,  # High reliability
            'market_rumors': 0.3           # Low reliability
        }
    
    def synthesize_conflicting_signals(self, evidence_sources: List[Dict]) -> Dict[str, Any]:
        """Synthesize conflicting evidence into balanced assessment."""
        
        conflicts = self._identify_conflicts(evidence_sources)
        
        synthesis = {
            'primary_conclusion': self._determine_primary_conclusion(evidence_sources),
            'confidence_level': self._calculate_confidence(evidence_sources, conflicts),
            'key_uncertainties': self._identify_uncertainties(conflicts),
            'supporting_evidence': self._categorize_supporting_evidence(evidence_sources),
            'contradictory_evidence': self._categorize_contradictory_evidence(evidence_sources),
            'resolution_rationale': self._explain_resolution_logic(conflicts)
        }
        
        return synthesis
    
    def _identify_conflicts(self, evidence_sources: List[Dict]) -> List[Dict]:
        """Identify specific conflicts between evidence sources."""
        
        conflicts = []
        
        # Financial health vs news sentiment conflicts
        financial_health = self._extract_financial_health_signals(evidence_sources)
        news_sentiment = self._extract_news_sentiment_signals(evidence_sources)
        
        if financial_health['signal'] == 'POSITIVE' and news_sentiment['signal'] == 'NEGATIVE':
            conflicts.append({
                'type': 'financial_vs_sentiment',
                'description': 'Strong financial metrics conflict with negative news sentiment',
                'evidence_1': financial_health,
                'evidence_2': news_sentiment,
                'severity': 'HIGH'
            })
        
        # Historical vs current performance conflicts
        historical_performance = self._extract_historical_signals(evidence_sources)
        current_metrics = self._extract_current_signals(evidence_sources)
        
        if self._signals_conflict(historical_performance, current_metrics):
            conflicts.append({
                'type': 'historical_vs_current',
                'description': 'Historical performance conflicts with current indicators',
                'evidence_1': historical_performance,
                'evidence_2': current_metrics,
                'severity': 'MEDIUM'
            })
        
        return conflicts
    
    def _determine_primary_conclusion(self, evidence_sources: List[Dict]) -> str:
        """Determine primary conclusion based on weighted evidence."""
        
        weighted_scores = []
        
        for source in evidence_sources:
            source_weight = self.evidence_weights.get(source['type'], 0.5)
            source_score = source.get('risk_score', 0.5)  # 0.0 = low risk, 1.0 = high risk
            
            weighted_scores.append(source_weight * source_score)
        
        overall_score = sum(weighted_scores) / sum(self.evidence_weights.values())
        
        if overall_score < 0.3:
            return 'LOW_RISK'
        elif overall_score < 0.7:
            return 'MEDIUM_RISK'
        else:
            return 'HIGH_RISK'
```

## Agent Response Templates with Cross-Domain Intelligence

### Risk Contagion Analysis Response Template
```python
def format_cross_domain_risk_response(analysis_results: Dict[str, Any], 
                                    user_query: str) -> str:
    """Format cross-domain risk analysis response with proper attribution."""
    
    response = f"""
**Cross-Domain Risk Analysis: {analysis_results['primary_entity']}**

**Ecosystem Risk Assessment**:
- **Shared Dependencies**: {analysis_results['shared_vendor_count']} common vendors/partners
- **Risk Contagion Potential**: {analysis_results['contagion_risk_level']}
- **Affected Portfolio Exposure**: €{analysis_results['total_exposure']:,.2f}

**Multi-Domain Risk Indicators**:

**Financial Risk** (Credit Analysis):
- Debt-to-Equity: {analysis_results['debt_to_equity']:.1f} (Warning: >3.0)
- Client Concentration: {analysis_results['client_concentration']:.0f}% (Breach: >70%)
- DSCR: {analysis_results['dscr']:.2f} (Breach: <1.25)

**Compliance Risk** (AML/KYC):
- AML Flags: {analysis_results['aml_flags']} active alerts
- KYC Status: {analysis_results['kyc_status']}
- Regulatory Status: {analysis_results['regulatory_status']}

**Market Intelligence** (News Analysis):
- Sentiment Score: {analysis_results['news_sentiment']:.2f} (-1.0 to 1.0 scale)
- Recent Article Count: {analysis_results['news_article_count']} (last 30 days)
- Key Themes: {', '.join(analysis_results['news_themes'])}

**Cross-Domain Intelligence Insights**:
{analysis_results['cross_domain_insights']}

**Risk Propagation Analysis**:
If {analysis_results['risk_vector']} experiences disruption:
- **Immediate Impact** (0-30 days): {analysis_results['immediate_impact']}
- **Medium-term Impact** (30-90 days): {analysis_results['medium_term_impact']}
- **Long-term Impact** (90+ days): {analysis_results['long_term_impact']}

**Contradictory Evidence Assessment**:
{analysis_results['contradictory_evidence_summary']}

**Recommended Actions**:
1. **Immediate**: {analysis_results['immediate_recommendations']}
2. **Short-term**: {analysis_results['short_term_recommendations']}
3. **Strategic**: {analysis_results['strategic_recommendations']}

**Data Sources**:
- Structured Analysis: Credit Risk Semantic View, Customer Risk Semantic View, Ecosystem Risk Semantic View
- Document Analysis: Compliance Documents, Credit Policies, News & Research
- External Data: {', '.join(analysis_results['external_data_sources'])}

**Audit Trail**: Analysis performed using {analysis_results['tools_used']} with {analysis_results['data_points_analyzed']} data points across {analysis_results['analysis_domains']} domains.
"""
    
    return response
```

## Performance Optimization for Cross-Domain Queries

### Query Optimization Patterns
```sql
-- Optimized cross-domain query with materialized CTEs
WITH MATERIALIZED vendor_relationships AS (
    SELECT 
        primary_entity_name,
        related_entity_name,
        relationship_strength,
        risk_impact_score
    FROM SEMANTIC_VIEW(
        BANK_AI_DEMO.SEMANTIC_LAYER.ecosystem_risk_sv
        METRICS average_risk_impact
        DIMENSIONS primary_entity_name, related_entity_name, relationship_strength
        FILTERS relationship_type = 'VENDOR'
    )
),
MATERIALIZED financial_metrics AS (
    SELECT 
        applicant_name,
        debt_to_equity,
        client_concentration,
        requested_amount
    FROM SEMANTIC_VIEW(
        BANK_AI_DEMO.SEMANTIC_LAYER.credit_risk_sv
        METRICS debt_to_equity, client_concentration, requested_amount
        DIMENSIONS applicant_name
    )
),
MATERIALIZED compliance_status AS (
    SELECT 
        entity_name,
        aml_flag_count,
        risk_rating
    FROM SEMANTIC_VIEW(
        BANK_AI_DEMO.SEMANTIC_LAYER.customer_risk_sv
        METRICS aml_flag_count
        DIMENSIONS entity_name, risk_rating
    )
)
SELECT 
    vr.primary_entity_name,
    vr.related_entity_name,
    vr.risk_impact_score,
    fm.debt_to_equity,
    fm.client_concentration,
    cs.aml_flag_count,
    -- Composite risk calculation
    (vr.risk_impact_score * 0.3 + 
     CASE WHEN fm.debt_to_equity > 3.0 THEN 0.4 ELSE 0.1 END +
     CASE WHEN cs.aml_flag_count > 0 THEN 0.3 ELSE 0.0 END) as composite_risk
FROM vendor_relationships vr
JOIN financial_metrics fm ON vr.primary_entity_name = fm.applicant_name
JOIN compliance_status cs ON vr.primary_entity_name = cs.entity_name
WHERE vr.relationship_strength IN ('PRIMARY', 'SECONDARY')
ORDER BY composite_risk DESC
LIMIT 10;
```

## Implementation Validation

### Cross-Domain Intelligence Testing Framework
```python
def validate_cross_domain_intelligence():
    """Validate cross-domain intelligence capabilities."""
    
    test_cases = [
        {
            'name': 'Vendor Risk Contagion',
            'query': "Which clients are affected if Northern Supply Chain Ltd fails?",
            'expected_domains': ['ecosystem_risk', 'credit_risk', 'customer_risk'],
            'expected_entities': ['Global Trade Ventures S.A.', 'Innovate GmbH', 'EuroTech Industries'],
            'validation_criteria': [
                'Identifies all affected clients',
                'Quantifies financial exposure',
                'Assesses compliance implications',
                'Provides risk mitigation recommendations'
            ]
        },
        {
            'name': 'Regulatory Impact Cascade',
            'query': "How does the new ESG directive affect our credit and compliance operations?",
            'expected_domains': ['regulatory_intelligence', 'credit_risk', 'customer_risk'],
            'expected_insights': ['Implementation costs', 'Affected applications', 'Compliance timeline'],
            'validation_criteria': [
                'Identifies regulatory requirements',
                'Maps impact to specific operations',
                'Quantifies implementation effort',
                'Provides compliance roadmap'
            ]
        },
        {
            'name': 'Contradictory Evidence Synthesis',
            'query': "Assess Innovate GmbH considering conflicting financial and news signals",
            'expected_domains': ['credit_risk', 'news_analysis', 'financial_data'],
            'expected_contradictions': ['Strong financials vs negative sentiment'],
            'validation_criteria': [
                'Identifies specific contradictions',
                'Weighs evidence appropriately',
                'Provides balanced assessment',
                'Explains resolution rationale'
            ]
        }
    ]
    
    return test_cases
```

This cross-domain intelligence architecture enables:

1. **Shared Ecosystem Understanding**: Realistic business relationship networks that create authentic risk contagion scenarios
2. **Multi-Step Reasoning**: Sophisticated analytical workflows that chain together evidence from multiple sources
3. **Contradictory Evidence Handling**: Balanced synthesis of conflicting signals with transparent reasoning
4. **Risk Propagation Modeling**: Understanding of how risks cascade through business networks
5. **Regulatory Impact Analysis**: Assessment of how policy changes affect multiple business functions
6. **Performance Optimization**: Efficient query patterns for complex cross-domain analysis
7. **Validation Framework**: Systematic testing of cross-domain intelligence capabilities
8. **Agent Orchestration**: Coordinated use of multiple tools and data sources for comprehensive analysis