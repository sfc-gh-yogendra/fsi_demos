use database fsi_demos;
use schema policy_wording;

ls @docs;

-- Step 1 Extract the text from the document, keep the format as is
CREATE OR REPLACE TABLE POLICY_WORDING_DOCS_RAW
AS
SELECT
    relative_path, 
    GET_PRESIGNED_URL(@docs, relative_path, 604800) as scoped_file_url, 
    SNOWFLAKE.CORTEX.PARSE_DOCUMENT(@docs, relative_path , {'mode': 'layout'}) as raw_text_dict,
    TO_VARCHAR(raw_text_dict:content) as raw_text
FROM DIRECTORY(@docs);

-- Verify the extraction, the raw_text_dict column has the json returned and raw_text has the markdown text
select * from POLICY_WORDING_DOCS_RAW LIMIT 5;

-- Step 2: Add metadata for each document using LLM, artcle explaining the advantge of doing so https://www.snowflake.com/en/engineering-blog/impact-retrieval-chunking-finance-rag/
CREATE OR REPLACE TABLE POLICY_WORDING_DOCS_METADATA AS (
    SELECT
        relative_path,
        --scoped_file_url,
        -- raw_text,
        AI_COMPLETE(
        'claude-4-sonnet', -- 'llama3.3-70b',
        'I am going to provide a document which will be indexed by a retrieval system containing many similar documents. I want you to provide key information associated with this document that can help differentiate this document in the index. Follow these instructions:
    1. Do not dwell on low level details. Only provide key high level information that a human might be expected to provide when searching for this doc.
    2. Do not use any formatting, just provide keys and values using a colon to separate key and value. Have each key and value be on a new line.\n\nDoc starts here:\n' 
    || raw_text || '\nDoc ends here\n\n') TEXT_METADATA,
    FROM
        POLICY_WORDING_DOCS_RAW
);

-- Check the meta data generated 
SELECT * FROM POLICY_WORDING_DOCS_METADATA LIMIT 5;

-- Step 3: Create the chunks and add the metadata to each chunk
CREATE OR REPLACE TABLE POLICY_WORDING_CONTEXTUALIZED_CHUNKS AS (
    WITH SPLIT_TEXT_CHUNKS AS (
        SELECT
            relative_path,
            scoped_file_url,
            C.VALUE AS CHUNK,
        FROM
           POLICY_WORDING_DOCS_RAW,
           LATERAL FLATTEN( input => SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER (
              raw_text,
              'none',
              1800, -- SET CHUNK SIZE
              300 -- SET CHUNK OVERLAP
           )) C
    )
    SELECT
        C.relative_path,
        C.scoped_file_url,
        CONCAT(M.TEXT_METADATA, '\n\n', C.CHUNK) AS CONTEXTUALIZED_CHUNK,
    FROM
        SPLIT_TEXT_CHUNKS C
    JOIN
        POLICY_WORDING_DOCS_METADATA M ON C.relative_path = M.relative_path);

-- Verify
select * from POLICY_WORDING_CONTEXTUALIZED_CHUNKS 
where RELATIVE_PATH = 'home_insurance_policy_wording_insurance_home_nhdhg6080_v35_012017_140617.pdf' 
limit 10;

-- Step 4: Create the Cortex Search service to be used for retrival https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/query-cortex-search-service
CREATE OR REPLACE CORTEX SEARCH SERVICE POLICY_WORDING_search_service
  ON CONTEXTUALIZED_CHUNK -- Indexed column that search is on
  ATTRIBUTES relative_path, scoped_file_url -- Fields that can be used for filtering
  WAREHOUSE = cortex_search_wh
  TARGET_LAG = '1 day'
  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'
  AS (
    SELECT
        CONTEXTUALIZED_CHUNK,
        relative_path,
        scoped_file_url
    FROM POLICY_WORDING_CONTEXTUALIZED_CHUNKS
);

-- Preview/Test the service
SELECT PARSE_JSON(
  SNOWFLAKE.CORTEX.SEARCH_PREVIEW(
      'POLICY_WORDING_search_service',
      '{
        "query": "What is the number of days for the notice period for the policy?",
        "columns":[
            "relative_path",
            "CONTEXTUALIZED_CHUNK"
        ],
        "filter": { "@eq": { "relative_path": "policywording_MComm.pdf" } }, 
        "limit":5
      }'
  )
)['results'] as results;

